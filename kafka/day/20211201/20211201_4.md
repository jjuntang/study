# 2021.12.01 Apache kafka 컨슈머 애플리케이션 개발, 실습

- Consumer 데이터를 가져가는 주체 (polling 으로)
- commit을 통해 읽은 consumer offset을 카프카에 기록   
어디까지 읽었는지 기록   
- 어디에 저장하나?
```
• FileSystem(.csv .log .tsv)
• Object Storage(S3, Minio)
• Hadoop(Hdfs, Hive)
• RDBMS(Oracle, Mysql)
• NoSql(MongoDB, CouchDB)
• 기타 다양한 저장소들(Elasticsearch, influxDB)
```

## simple-kafka-consumer 프로젝트 실습
- 실습   
16 번 커맨드를 이용하여 데이터 produce 함
```bash
./kafka-console-producer.sh --bootstrap-server {aws ec2 public ip}:9092 --topic test
```
```
1
2
3
4
```


```java
consumer.poll(Duration.ofSeconds(1));
```
1 초 주기로 데이터를 가져옴   

## kafka-consumer-auto-commit
커밋 : 컨슈머가 어디까지 읽었는지 브로커에 알려주는 것   
```java
configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);
configs.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 60000);
```

## consumer commit
- consumer 가 비 정상적으로 종료되었을 때 다시 실행하면 동기화 문제 발생할 수 있음.
- p.93   
enable.auto.commit=true   
속도가 가장 빠름   
중복 또는 유실이 발생할 수 있음   
중복/유실을 허용하지 않는 곳(은행, 카드 등)에서는 사용하면 안됨!!   
일부 데이터가 중복/유실되도 상관 없는 곳(센서, GPS 등)에서 사용  
- p.94
- p.95    
데이터 중복처리? 무슨 문제지?   
```
커머스의 장바구니 시스템에서 중복 이슈 발생
👉 나는 장바구니에 1개 상품을 담았는데 2개 상품이 담김
카드사의 결제 시스템에서 중복 이슈 발생
👉 편의점에서 아이스크림 결제를 했는데 2번 결재됨
• 택배사 SMS 발송 시스템에서 중복 이슈 발생
👉 집에 도착 했다는 SMS가 2번 발송
```

- p.99

```
• enable.auto.commit=false
1) commitSync() : 동기 커밋 - 커밋이 완료된 이후 다음 데이터 처리
- ConsumerRecord 처리 순서를 보장함
- 가장 느림(커밋이 완료될 때 까지 block)
- poll() 메서드로 반환된 ConsumerRecord의 마지막 offset을 커밋
- Map<TopicPartition, OffsetAndMetadata> 을 통해 오프셋 지정 커밋 가능
==> 즉 만약 50개의 들어온 후에 맵에 있는 데이터를 한개씩 커밋함
```

```
2) commitAsync() : 비동기 커밋 - 커밋 처리하는 동안 다음 데이터 처리
- 동기 커밋보다 빠름
- 중복이 발생할 수 있음
👉 일시적인 통신 문제로 이전 offset보다 이후 offset이 먼저 커밋 될 때
- ConsumerRecord 처리 순서를 보장하지 못함
👉 처리 순서가 중요한 서비스(주문, 재고관리 등)에서는 사용 제한
```

## kafka-consumer-sync-commit 프로젝트 실습
```java
configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
```
```java
consumer.commitSync();
```

## Consumer rebalance
- p.103   
```
리밸런스 - 컨슈머 그룹의 파티션 소유권이 변경될 때 일어나는 현상
• 리밸런스를 하는 동안 일시적으로 메시지를 가져올 수 없음
• 리밸런스 발생시 데이터 유실/중복 발생 가능성 있음
👉 commitSync() 또는 추가적인 방법(unique key)으로 데이터 유실/중복 방지
• 언제 리밸런스 발생?
👉 consumer.close() 호출시 또는 consumer의 세션이 끊어졌을 때
```  

## Consumer rebalance listener

## Consumer wakeup (동영상 21:09)
- consumer 를 정상적으로 종료시켜야 할때 사용하는 매서드
- p.105 : 정상 동작의 경우
- p.106, 107 : SIGKILL 시그널이 발생하여 consumer 가 종료되는 경우 
```
101번~150번 오프셋 처리완료, 151번 오프셋~200번 오프셋 미처리
```
```
브로커에는 100번 오프셋이 마지막 커밋
👉 컨슈머 재시작, 다시 오프셋 101부터 처리 시작, 101번~150번 중복처리
```
===> 이걸 안전하게 처리하기 위한 방법
```java
Runtime.getRuntime().addShutdownHook(new Thread() {
    public void run() {
        consumer.wakeup();
    }
});
```
```java
try {
    while (true) {
        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));
        for (ConsumerRecord<String, String> record : records) {
            System.out.println(record.value());
        }
        consumer.commitSync();
    }
} catch (WakeupException e) {
    System.out.println("poll() method trigger WakeupException");
}finally {
    consumer.commitSync();
    consumer.close();
}
```

## Consumer thread 전략
- p.110 : 1안) 1 프로세스 + 1 스레드(컨슈머)
- p.111 : 2안) 1 프로세스 + n 스레드(동일 컨슈머 그룹)
- p.112 : 1 프로세스 + n 스레드(다수 컨슈머 그룹)
- p.113 : 강사가 선택한 전략 - 1개의 스레드에 여러개의 스레드를 사용

## kafka-consumer-multi-thread 프로젝트 실습
D:\01_study\kafka\prj\tacademy-kafka\kafka-consumer-multi-thread

## consumer lag
### lag  이 얼마나 발생하는지 파악하는 법
### 외부 소프트웨어를 이용하여 그래프로 시각화 하여 파악
- p.115
- p.116   
```
• 컨슈머 랙은 컨슈머의 상태를 나타내는 지표.
• 컨슈머 랙의 최대값은 컨슈머 인스턴스를 통해 직접 확인할 수 있음
  • consumer.metrics()를 통해 확인할 수 있는 지표
    • records-lag-max : 토픽의 파티션 중 최대 랙
    • fetch-size-avg : 1번 polling하여 가져올 때 레코드 byte평균
    • fetch-rate : 1초 동안 레코드 가져오는 회수
    • ...
```
- p.117
```
컨슈머 컨슈머 인스턴스를 통한 컨슈머 랙 수집의 문제점
• 컨슈머 인스턴스 장애가 발생하면 지표 수집 불가능
    • 구현하는 컨슈머마다 지표를 수집하는 로직 개발 필요
    • 컨슈머 랙 최대값(records-lag-max) 만 알 수 있음
    👉 토픽에 파티션은 n개가 있을 수 있음.
    👉 최대값을 제외한 나머지 파티션의 컨슈머 랙은 알 수 없음
```
- p.118
```
• 컨슈머 랙 모니터링
    👉 외부 모니터링 애플리케이션을 사용하세요!
    👉 Confluent Platform, Datadog, Kafka Burrow(Open source)
• 카프카 버로우
    👉 https://github.com/linkedin/Burrow
        • Linkedin에서 오픈소스로 제공하는 컨슈머 랙 체크 툴
        • 버로우 실행 시 Kafka, Zookeeper정보를 통해 랙 정보 자체 수집
        • 슬라이딩 윈도우를 통한 컨슈머 상태 정의
            • OK : 정상
            • ERROR : 컨슈머가 polling을 멈춤
            • WARNING : 컨슈머가 polling을 수행하지만 lag이 계속 증가
        • 버로우 설치 및 운영방법
        👉 https://blog.voidmainvoid.net/279
```

[버로우 설치 및 운영방법](https://blog.voidmainvoid.net/279)

